<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xml:lang="en-us" lang="en-us">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <meta name="abstract" content="This chapter discusses the sharding methods supported by Oracle Sharding, how to choose a method, and how to use subpartitioning.">
      <meta name="description" content="This chapter discusses the sharding methods supported by Oracle Sharding, how to choose a method, and how to use subpartitioning.">
      <title>Sharding Methods</title>
      <meta property="og:site_name" content="Oracle Help Center">
      <meta property="og:title" content="Database Administrator’s Guide ">
      <meta property="og:description" content="This chapter discusses the sharding methods supported by Oracle Sharding, how to choose a method, and how to use subpartitioning.">
      <link rel="stylesheet" href="/sp_common/book-template/ohc-book-template/css/book.css">
      <link rel="shortcut icon" href="/sp_common/book-template/ohc-common/img/favicon.ico">
      <meta name="application-name" content="Database Administrator’s Guide">
      <meta name="generator" content="DITA Open Toolkit version 1.8.5 (Mode = doc)">
      <meta name="plugin" content="SP_docbuilder HTML plugin release 18.2.2">
      <link rel="alternate" href="database-administrators-guide.pdf" title="PDF File" type="application/pdf">
      <meta name="robots" content="all">
      <link rel="schema.dcterms" href="http://purl.org/dc/terms/">
      <meta name="dcterms.created" content="2018-03-29T07:20:19-07:00">
      
      <meta name="dcterms.dateCopyrighted" content="2001, 2018">
      <meta name="dcterms.category" content="database">
      <meta name="dcterms.identifier" content="E85760-06">
      
      <meta name="dcterms.product" content="en/database/oracle/oracle-database/12.2">
      <meta name="dcterms.release" content="Release 12.2">
      <link rel="prev" href="sharding-physical-organization.html" title="Previous" type="text/html">
      <link rel="next" href="sharding-application-development.html" title="Next" type="text/html">
      <script>
        document.write('<style type="text/css">');
        document.write('body > .noscript, body > .noscript ~ * { visibility: hidden; }');
        document.write('</style>');
     </script>
      <script data-main="/sp_common/book-template/ohc-book-template/js/book-config" src="/sp_common/book-template/requirejs/require.js"></script>
      <script>
            if (window.require === undefined) {
                document.write('<script data-main="sp_common/book-template/ohc-book-template/js/book-config" src="sp_common/book-template/requirejs/require.js"><\/script>');
                document.write('<link href="sp_common/book-template/ohc-book-template/css/book.css" rel="stylesheet"/>');
            }
        </script>
      <script type="application/json" id="ssot-metadata">{"primary":{"category":{"short_name":"database","element_name":"Database","display_in_url":true},"suite":{"short_name":"oracle","element_name":"Oracle","display_in_url":true},"product_group":{"short_name":"not-applicable","element_name":"Not applicable","display_in_url":false},"product":{"short_name":"oracle-database","element_name":"Oracle Database","display_in_url":true},"release":{"short_name":"12.2","element_name":"Release 12.2","display_in_url":true}}}</script>
      
    <meta name="dcterms.title" content="Database Administrator's Guide">
    <meta name="dcterms.isVersionOf" content="ADMIN">
  </head>
   <body>
      <div class="noscript alert alert-danger text-center" role="alert">
         <a href="sharding-physical-organization.html" class="pull-left"><span class="glyphicon glyphicon-chevron-left" aria-hidden="true"></span>Previous</a>
         <a href="sharding-application-development.html" class="pull-right">Next<span class="glyphicon glyphicon-chevron-right" aria-hidden="true"></span></a>
         <span class="fa fa-exclamation-triangle" aria-hidden="true"></span> JavaScript must be enabled to correctly display this content
        
      </div>
      <article>
         <header>
            <ol class="breadcrumb" vocab="http://schema.org/" typeof="BreadcrumbList">
               <li property="itemListElement" typeof="ListItem"><a href="index.html" property="item" typeof="WebPage"><span property="name">Database Administrator’s Guide </span></a></li>
               <li property="itemListElement" typeof="ListItem"><a href="shard_part.html" property="item" typeof="WebPage"><span property="name">Sharded Database Management</span></a></li>
               <li class="active" property="itemListElement" typeof="ListItem">Sharding Methods</li>
            </ol>
            <a id="GUID-3B07D91C-CEAA-4170-A94B-ACF47BEE617B" name="GUID-3B07D91C-CEAA-4170-A94B-ACF47BEE617B"></a>
            
            <h2 id="ADMIN-GUID-3B07D91C-CEAA-4170-A94B-ACF47BEE617B" class="sect2"><span class="enumeration_chapter">52 </span>Sharding Methods
            </h2>
         </header>
         <div class="ind">
            <div>
               <p>This chapter discusses the sharding methods supported by Oracle Sharding, how to choose a method, and how to use subpartitioning.</p>
               <p>The following topics describe the sharding methods supported by Oracle Sharding:</p>
            </div>
            <div>
               <ul class="ullinks">
                  <li class="ulchildlink"><a href="sharding-methods.html#GUID-37F20817-EFD5-400B-A082-41171C0B6D1C">System-Managed Sharding</a><br>System-managed sharding is a sharding method which does not require the user to specify mapping of data to shards. Data is automatically distributed across shards using partitioning by consistent hash. The partitioning algorithm evenly and randomly distributes data across shards.
                  </li>
                  <li class="ulchildlink"><a href="sharding-methods.html#GUID-1FCC7F96-59BF-4C8D-B71A-6A307D7283EA">Composite Sharding</a><br>The composite sharding method allows you to create multiple shardspaces for different subsets of data in a table partitioned by consistent hash. A <span class="italic">shardspace</span> is set of shards that store data that corresponds to a range or list of key values.
                  </li>
                  <li class="ulchildlink"><a href="sharding-methods.html#GUID-11AE3897-003D-4723-89C4-23AD5A837B89">Using Subpartitions with Sharding</a><br>Because Oracle Sharding is based on table partitioning, all of the subpartitioning methods provided by Oracle Database are also supported for sharding. 
                  </li>
               </ul>
            </div>
            
            <div class="sect2"><a id="GUID-37F20817-EFD5-400B-A082-41171C0B6D1C" name="GUID-37F20817-EFD5-400B-A082-41171C0B6D1C"></a><h3 id="ADMIN-GUID-37F20817-EFD5-400B-A082-41171C0B6D1C" class="sect3"><span class="enumeration_section">52.1 </span>System-Managed Sharding
               </h3>
               <div>
                  <p>System-managed sharding is a sharding method which does not require the user to specify mapping of data to shards. Data is automatically distributed across shards using partitioning by consistent hash. The partitioning algorithm evenly and randomly distributes data across shards.</p>
                  <p>The distribution used in system-managed sharding is intended to eliminate hot spots and provide uniform performance across shards. Oracle Sharding automatically maintains the balanced distribution of chunks when shards are added to or removed from an SDB.</p>
                  <p>Consistent hash is a partitioning strategy commonly used in scalable distributed systems. It is different from traditional hash partitioning. With traditional hashing, the bucket number is calculated as <code class="codeph">HF(key) % N</code> where HF is a hash function and N is the number of buckets. This approach works fine if N is constant, but requires reshuffling of all data when N changes.
                  </p>
                  <p>More advanced algorithms, such as linear hashing, do not require rehashing of the entire table to add a hash bucket, but they impose restrictions on the number of buckets, such as the number of buckets can only be a power of 2, and on the order in which the buckets can be split.</p>
                  <p>The implementation of consistent hashing used in Oracle Sharding avoids these limitations by dividing the possible range of values of the hash function (for example. from 0 to 2<sup>32</sup>) into a set of N adjacent intervals, and assigning each interval to a chunk , as shown in the figure below. In this example, the SDB contains 1024 chunks, and each chunk gets assigned a range of 2<sup>22  </sup>hash values. Therefore partitioning by consistent hash is essentially partitioning by the range of hash values.
                  </p>
                  <div class="figure" id="GUID-37F20817-EFD5-400B-A082-41171C0B6D1C__GUID-C7895345-3AAF-40F1-AA8D-08E52E8F4593">
                     <p class="titleinfigure">Figure 52-1 Ranges of Hash Values Assigned to Chunks</p><img src="img/admin_3v_127a.png" alt="Description of Figure 52-1 follows" title="Description of Figure 52-1 follows" longdesc="img_text/admin_3v_127a.html"><br><a href="img_text/admin_3v_127a.html">Description of "Figure 52-1 Ranges of Hash Values Assigned to Chunks"</a></div>
                  <!-- class="figure" -->
                  <p>Assuming that all of the shards have the same computing power, an equal number of chunks is assigned to each shard in the SDB. For example, if 1024 chunks are created in an SDB that contains 16 shards, each shard will contain 64 chunks.</p>
                  <p>In the event of resharding, when shards are added to or removed from an SDB, some of the chunks are relocated among the shards to maintain an even distribution of chunks across the shards. The contents of the chunks does not change during this process; no rehashing takes place.</p>
                  <p>When a chunk is split, its range of hash values is divided into two ranges, but nothing needs to be done for the rest of the chunks. Any chunk can be independently split at any time.</p>
                  <p>All of the components of an SDB that are involved in directing connection requests to shards maintain a routing table that contains a list of chunks hosted by each shard and ranges of hash values associated with each chunk. To determine where to route a particular database request, the routing algorithm applies the hash function to the provided value of the sharding key, and maps the calculated hash value to the appropriate chunk, and then to a shard that contains the chunk.</p>
                  <p>The number of chunks in an SDB with system-managed sharding can be specified in the <code class="codeph">CREATE SHARDCATALOG</code> command. If not specified, the default value, 120 chunks per shard, is used. Once an SDB is deployed, the number of chunks can only be changed by splitting chunks.
                  </p>
                  <p>Before creating a sharded table partitioned by consistent hash, a set of tablespaces (one tablespace per chunk) has to be created to store the table partitions. The tablespaces are automatically created by executing the SQL statement, <code class="codeph">CREATE TABLESPACE SET</code>. 
                  </p>
                  <p>All of the tablespaces in a tablespace set have the same physical attributes and can only contain Oracle Managed Files (OMF). In its simplest form, the <code class="codeph">CREATE TABLESPACE SET</code> statement has only one parameter, the name of the tablespace set, for example:
                  </p><pre class="pre codeblock"><code>CREATE TABLESPACE SET ts1;</code></pre><p>In this case each tablespace in the set contains a single OMF file with default attributes. To customize tablespace attributes, the <code class="codeph">USING TEMPLATE</code> clause (shown in the example below) is added to the statement. The <code class="codeph">USING TEMPLATE</code> clause specifies attributes that apply to each tablespace in the set.  
                  </p><pre class="pre codeblock"><code>CREATE TABLESPACE SET ts1
USING TEMPLATE
( 
 DATAFILE SIZE 10M
 EXTENT MANAGEMENT LOCAL UNIFORM SIZE 256K
 SEGMENT SPACE MANAGEMENT AUTO
 ONLINE
)
;</code></pre><p>After a tablespace set has been created, a table partitioned by consistent hash can be created with partitions stored in the tablespaces that belong to the set. The <code class="codeph">CREATE TABLE</code> statement might look as follows:
                  </p><pre class="pre codeblock"><code>CREATE SHARDED TABLE customers 
( cust_id     NUMBER NOT NULL
, name        VARCHAR2(50)
, address     VARCHAR2(250) 
, location_id VARCHAR2(20)
, class       VARCHAR2(3)
, signup      DATE
, CONSTRAINT cust_pk PRIMARY KEY(cust_id)
)
PARTITION BY CONSISTENT HASH (cust_id)
PARTITIONS AUTO
TABLESPACE SET ts1
;</code></pre><p><code class="codeph">PARTITIONS AUTO</code> in this statement means that the number of partitions is automatically set to the number of tablespaces in the tablespace set <code class="codeph">ts1</code> (which is equal to the number of chunks) and each partition will be stored in a separate tablespace. 
                  </p>
                  <p>Each tablespace in a tablespace set belongs to a distinct chunk. In the other words, a chunk can contain only one tablespace from a given tablespace set. However, the same tablespace set can be used for multiple tables that belong to the same table family. In this case, each tablespace in the set will store multiple partitions, one from each table. </p>
                  <p>Alternatively, each table in a table family can be stored in a separate tablespace set. In this case, a chunk contains multiple tablespaces, one from each tablespace set with each tablespace storing a single partition.</p>
                  <p>The following figure illustrates the relationship between partitions, tablespaces, and shards for a use case with a single sharded table. In this case, each chunk contains a single tablespace, and each tablespace stores a single partition.</p>
                  <div class="figure" id="GUID-37F20817-EFD5-400B-A082-41171C0B6D1C__GUID-BFB73823-F61F-4BBA-A484-83DE345F4875">
                     <p class="titleinfigure">Figure 52-2 System-Managed Sharding</p><img src="img/admin_3v_128a.png" alt="Description of Figure 52-2 follows" title="Description of Figure 52-2 follows" longdesc="img_text/admin_3v_128a.html"><br><a href="img_text/admin_3v_128a.html">Description of "Figure 52-2 System-Managed Sharding"</a></div>
                  <!-- class="figure" -->
                  <div class="infoboxnote" id="GUID-37F20817-EFD5-400B-A082-41171C0B6D1C__GUID-13087058-EABF-44FF-A3C0-99844EC01E4F">
                     <p class="notep1">Note:</p>The sharding method is specified in the <code class="codeph">GDSCTL CREATE SHARDCATALOG</code> command and cannot be changed later.
                  </div>
               </div>
            </div>
            <div class="sect2"><a id="GUID-1FCC7F96-59BF-4C8D-B71A-6A307D7283EA" name="GUID-1FCC7F96-59BF-4C8D-B71A-6A307D7283EA"></a><h3 id="ADMIN-GUID-1FCC7F96-59BF-4C8D-B71A-6A307D7283EA" class="sect3"><span class="enumeration_section">52.2 </span>Composite Sharding
               </h3>
               <div>
                  <p>The composite sharding method allows you to create multiple shardspaces for different subsets of data in a table partitioned by consistent hash. A <span class="italic">shardspace</span> is set of shards that store data that corresponds to a range or list of key values.
                  </p>
                  <p>System-managed sharding uses partitioning by consistent hash to distribute rows across shards in a shardgroup. However, system-managed sharding does not give you any control over the assignment of data to shards.</p>
                  <p>When sharding by consistent hash on a primary key, there is often a requirement to differentiate subsets of data within an SDB in order to store them in different geographic locations, allocate to them different hardware resources, or configure high availability and disaster recovery differently. Usually this differentiation is done based on the value of another (non-primary) column, for example, customer location or a class of service.</p>
                  <p>With composite sharding, data is first partitioned by list or range across multiple shardspaces, and then further partitioned by consistent hash across multiple shards in each shardspace.</p>
                  <p>The two levels of sharding make it possible to automatically maintain balanced distribution of chunks across shards in each shardspace, and, at the same time, partition data across shardspaces. </p>
                  <p>For example, suppose you want to allocate three shards hosted on faster servers to “gold” customers and four shards hosted on slower machines to “silver” customers. Within each set of shards, customers have to be distributed using partitioning by consistent hash on customer ID.</p>
                  <div class="figure" id="GUID-1FCC7F96-59BF-4C8D-B71A-6A307D7283EA__GUID-308B8722-D0E6-4C9C-93E3-B6157A115686">
                     <p class="titleinfigure">Figure 52-3 Composite Sharding</p><img src="img/admin_3v_131a.png" alt="Description of Figure 52-3 follows" title="Description of Figure 52-3 follows" longdesc="img_text/admin_3v_131a.html"><br><a href="img_text/admin_3v_131a.html">Description of "Figure 52-3 Composite Sharding"</a></div>
                  <!-- class="figure" -->
                  <p>Two shardspaces need to be created for such a configuration, using the following GDSCTL commands:</p><pre class="pre codeblock"><code>ADD SHARDSPACE &#x2013;SHARDSPACE shspace1;
ADD SHARDSPACE &#x2013;SHARDSPACE shspace2;

ADD SHARD &#x2013;CONNECT shard1 &#x2013;SHARDSPACE shspace1;
ADD SHARD &#x2013;CONNECT shard2 &#x2013;SHARDSPACE shspace1;
ADD SHARD &#x2013;CONNECT shard3 &#x2013;SHARDSPACE shspace1;

ADD SHARD &#x2013;CONNECT shard4 &#x2013;SHARDSPACE shspace2;
ADD SHARD &#x2013;CONNECT shard5 &#x2013;SHARDSPACE shspace2;
ADD SHARD &#x2013;CONNECT shard6 &#x2013;SHARDSPACE shspace2;
ADD SHARD &#x2013;CONNECT shard7 &#x2013;SHARDSPACE shspace2;</code></pre><p>With composite sharding, as with the other sharding methods, tablespaces are used to specify the mapping of partitions to shards. To place subsets of data in a sharded table into different shardspaces, a separate tablespace set must be created in each shardspace as shown in the following example.</p><pre class="pre codeblock"><code>CREATE TABLESPACE SET tbs1 IN SHARDSPACE shspace1;
CREATE TABLESPACE SET tbs2 IN SHARDSPACE shspace2;</code></pre><p>To store user-defined subsets of data in different tablespaces, Oracle Sharding provides syntax to group partitions into sets and associate each set of partitions with a tablespace set. Support for partition sets can be considered a logical equivalent of a higher level of partitioning which is implemented on top of partitioning by consistent hash.</p>
                  <p>The statement in the following example partitions a sharded table into two partition sets: gold and silver, based on class of service. Each partition set is stored in a separate tablespace. Then data in each partition set is further partitioned by consistent hash on customer ID. </p><pre class="pre codeblock"><code>CREATE SHARDED TABLE customers
( cust_id NUMBER NOT NULL
, name VARCHAR2(50)
, address VARCHAR2(250) 
, location_id VARCHAR2(20) 
, class VARCHAR2(3) 
, signup_date DATE 
, CONSTRAINT cust_pk PRIMARY KEY(class, cust_id) 
)
<span class="bold">PARTITIONSET BY LIST</span> (class) 
  PARTITION BY CONSISTENT HASH (cust_id)
  PARTITIONS AUTO
<span class="bold">(PARTITIONSET gold VALUES (‘gld’) TABLESPACE SET tbs1,</span>
<span class="bold"> PARTITIONSET silver VALUES (‘slv’) TABLESPACE SET tbs2</span>)
;</code></pre><div class="infoboxnote" id="GUID-1FCC7F96-59BF-4C8D-B71A-6A307D7283EA__GUID-903581CA-34E4-45C9-93AB-90D2D658BE8D">
                     <p class="notep1">Note:</p>In Oracle Database 12<span class="italic">c</span> Release 2 only a single partition set from a table can be stored in a shardspace.
                     <p>The sharding method is specified in the <code class="codeph">GDSCTL CREATE SHARDCATALOG</code> command and cannot be changed later.
                     </p>
                  </div>
               </div>
            </div>
            <div class="sect2"><a id="GUID-11AE3897-003D-4723-89C4-23AD5A837B89" name="GUID-11AE3897-003D-4723-89C4-23AD5A837B89"></a><h3 id="ADMIN-GUID-11AE3897-003D-4723-89C4-23AD5A837B89" class="sect3"><span class="enumeration_section">52.3 </span>Using Subpartitions with Sharding
               </h3>
               <div>
                  <p>Because Oracle Sharding is based on table partitioning, all of the subpartitioning methods provided by Oracle Database are also supported for sharding. </p>
                  <p>Subpartitioning splits each partition into smaller parts and may be beneficial for efficient parallel execution within a shard, especially in the case of sharding by range or list when the number of partitions per shard may be small.</p>
                  <p>From a manageability perspective, subpartitioning makes it possible to support the tiered storage approach by putting subpartitions into separate tablespaces and moving them between storage tiers. Migration of subpartitions between storage tiers can be done without sacrificing the scalability and availability benefits of sharding and the ability to perform partition pruning and partition-wise joins on a primary key.</p>
                  <p>The following example shows system-managed sharding by consistent hash combined with subpartitioning by range. </p><pre class="pre codeblock"><code>CREATE SHARDED TABLE customers 
( cust_id     NUMBER NOT NULL
, name        VARCHAR2(50)
, address     VARCHAR2(250)
, location_id VARCHAR2(20)
, class       VARCHAR2(3)
, signup_date DATE
, CONSTRAINT cust_pk PRIMARY KEY(cust_id, signup_date)
)
TABLESPACE SET ts1
PARTITION BY CONSISTENT HASH (cust_id)
<span class="bold">SUBPARTITION BY RANGE (signup_date)</span>
<span class="bold">SUBPARTITION TEMPLATE</span> 
<span class="bold">( SUBPARTITION per1 VALUES LESS THAN (TO_DATE('01/01/2000','DD/MM/YYYY')),</span>
  <span class="bold">SUBPARTITION per2 VALUES LESS THAN (TO_DATE('01/01/2010','DD/MM/YYYY')),</span>
  <span class="bold">SUBPARTITION per3 VALUES LESS THAN (TO_DATE('01/01/2020','DD/MM/YYYY')),</span>
  <span class="bold">SUBPARTITION future VALUES LESS THAN (MAXVALUE))</span>
<span class="bold">)</span>
PARTITIONS AUTO
;</code></pre><p>The following figure offers a graphical view of the table created by this statement.</p>
                  <div class="figure" id="GUID-11AE3897-003D-4723-89C4-23AD5A837B89__GUID-14178DD1-D520-4895-87C2-5D6473C48256">
                     <p class="titleinfigure">Figure 52-4 Subpartitions Stored in the Tablespace of the Parent Partition</p><img src="img/admin_3v_130a.png" alt="Description of Figure 52-4 follows" title="Description of Figure 52-4 follows" longdesc="img_text/admin_3v_130a.html"><br><a href="img_text/admin_3v_130a.html">Description of "Figure 52-4 Subpartitions Stored in the Tablespace of the Parent Partition"</a></div>
                  <!-- class="figure" -->
                  <p>In this example each subpartition is stored in the parent partition’s tablespace. Because subpartitioning is done by date, it makes more sense to store subpartitions in separate tablespaces to provide the ability to archive older data or move it to a read-only storage. The appropriate syntax is shown here.</p><pre class="pre codeblock"><code>CREATE SHARDED TABLE customers 
( cust_id     NUMBER NOT NULL
, name        VARCHAR2(50)
, address     VARCHAR2(250) 
, location_id VARCHAR2(20)
, class       VARCHAR2(3)
, signup_date DATE NOT NULL
 , CONSTRAINT cust_pk PRIMARY KEY(cust_id, signup_date)
)
PARTITION BY CONSISTENT HASH (cust_id)
<span class="bold">SUBPARTITION BY RANGE(signup_date)
SUBPARTITION TEMPLATE 
( SUBPARTITION per1 VALUES LESS THAN (TO_DATE('01/01/2000','DD/MM/YYYY'))
       TABLESPACE SET ts1,
  SUBPARTITION per2 VALUES LESS THAN (TO_DATE('01/01/2010','DD/MM/YYYY'))
       TABLESPACE SET ts2,
  SUBPARTITION per3 VALUES LESS THAN (TO_DATE('01/01/2020','DD/MM/YYYY'))
       TABLESPACE SET ts3,
  SUBPARTITION future VALUES LESS THAN (MAXVALUE)) 
       TABLESPACE SET ts4
)
</span>PARTITIONS AUTO
;</code></pre><p>Note that in the case of a database that is not sharded, when tablespaces are specified in the subpartition template it means that subpartition N from every partition is stored in the same tablespace. This is different in case of sharding when subpartitions that belong to the different partitions must be stored in separate tablespaces so that they can be moved in the event of resharding.</p>
                  <p>Subpartitioning can be used with composite sharding, too. In this case data in a table is organized in three levels: partition sets, partitions, and subpartitions. Examples of the three levels of data organization are shown below.</p><pre class="pre codeblock"><code>CREATE SHARDED TABLE customers 
( cust_id     NUMBER NOT NULL
, name        VARCHAR2(50)
, address     VARCHAR2(250) 
, location_id VARCHAR2(20)
, class       VARCHAR2(3) NOT NULL
, signup_date DATE NOT NULL
, CONSTRAINT cust_pk PRIMARY KEY(class, cust_id, signup_date)
)
<span class="bold">PARTITIONSET BY LIST (class)</span>
PARTITION BY CONSISTENT HASH (cust_id)
SUBPARTITION BY RANGE (signup_date)
SUBPARTITION TEMPLATE /* applies to both SHARDSPACEs */
( SUBPARTITION per1 VALUES LESS THAN (TO_DATE('01/01/2000','DD/MM/YYYY'))
, SUBPARTITION per2 VALUES LESS THAN (TO_DATE('01/01/2010','DD/MM/YYYY'))
, SUBPARTITION per3 VALUES LESS THAN (TO_DATE('01/01/2020','DD/MM/YYYY'))
, SUBPARTITION future VALUES LESS THAN (MAXVALUE))
)
PARTITIONS AUTO
<span class="bold">(
  PARTITIONSET gold   VALUES (‘gld’) TABLESPACE SET tbs1
, PARTITIONSET silver VALUES (‘slv’) TABLESPACE SET tbs2
)
</span>;</code></pre><p>In this example, subpartitions are stored in the tablespace of the parent partition, and the subpartition template is the same for each <code class="codeph">PARTITIONSET</code>. To store subpartitions in separate tablespaces the following syntax can be used.
                  </p><pre class="pre codeblock"><code>CREATE SHARDED TABLE customers 
( cust_id     NUMBER NOT NULL
, name        VARCHAR2(50)
, address     VARCHAR2(250) 
, location_id VARCHAR2(20)
, class       VARCHAR2(3) NOT NULL
, signup_date DATE NOT NULL
, CONSTRAINT cust_pk PRIMARY KEY(class, cust_id, signup_date)
)
<span class="bold">PARTITIONSET BY LIST (class)
</span>PARTITION BY CONSISTENT HASH (cust_id)
SUBPARTITION BY RANGE (signup_date)
PARTITIONS AUTO
 (
  <span class="bold">PARTITIONSET gold   VALUES (‘gld’)
</span>   SUBPARTITION TEMPLATE
   ( SUBPARTITION per1 VALUES LESS THAN (TO_DATE('01/01/2000','DD/MM/YYYY'))
      TABLESPACE SET tbs1
   , SUBPARTITION per2 VALUES LESS THAN (TO_DATE('01/01/2010','DD/MM/YYYY')) 
      TABLESPACE SET tbs2
   , SUBPARTITION per3 VALUES LESS THAN (TO_DATE('01/01/2020','DD/MM/YYYY')) 
      TABLESPACE SET tbs3
   , SUBPARTITION future VALUES LESS THAN (MAXVALUE)) 
      TABLESPACE SET tbs4 
   )
<span class="bold">, PARTITIONSET silver VALUES (‘slv’) TABLESPACE SET ts1
</span>   SUBPARTITION TEMPLATE
   ( SUBPARTITION per1 VALUES LESS THAN (TO_DATE('01/01/2000','DD/MM/YYYY'))
      TABLESPACE SET tbs5
   , SUBPARTITION per2 VALUES LESS THAN (TO_DATE('01/01/2010','DD/MM/YYYY')) 
      TABLESPACE SET tbs6
   , SUBPARTITION per3 VALUES LESS THAN (TO_DATE('01/01/2020','DD/MM/YYYY')) 
      TABLESPACE SET tbs7
   , SUBPARTITION future VALUES LESS THAN (MAXVALUE)) 
      TABLESPACE SET tbs8 
   )
)
; </code></pre></div>
            </div>
         </div>
      </article>
   </body>
</html>